{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be1ec52",
   "metadata": {},
   "source": [
    "# EDSA - Climate Change Belief Analysis 2022\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9cf75",
   "metadata": {},
   "source": [
    "---\n",
    "### Honour Code\n",
    "\n",
    "We {**Team 10**}, confirm - by submitting this document - that the solutions in this notebook are a result of our own work and that we abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3241644",
   "metadata": {},
   "source": [
    "### Predict Overview: Predict an individual’s belief in climate change based on historical tweet data\n",
    "\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "With this context, we have created a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79045d1",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Feature Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Classifier Model Selection</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453d7b1",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293ba799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dianaokeyo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dianaokeyo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn import preprocessing as p\n",
    "import nltk\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer, PorterStemmer\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, log_loss\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599e0d3",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e41f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the train data and view the first few entries\n",
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9b033b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a52e9b",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237fff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20691459",
   "metadata": {},
   "source": [
    "We observed that our dataset has 3 columns and a total of 15,819 rows. We also observed the dataset contains two numerical varibles and one categorical variable. We also observed that the size of the data is 370.9+ KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff72197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15819.000000</td>\n",
       "      <td>15819.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.917504</td>\n",
       "      <td>501719.433656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836537</td>\n",
       "      <td>289045.983132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>253207.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>502291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>753769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>999888.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment        tweetid\n",
       "count  15819.000000   15819.000000\n",
       "mean       0.917504  501719.433656\n",
       "std        0.836537  289045.983132\n",
       "min       -1.000000       6.000000\n",
       "25%        1.000000  253207.500000\n",
       "50%        1.000000  502291.000000\n",
       "75%        1.000000  753769.000000\n",
       "max        2.000000  999888.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85d7e9",
   "metadata": {},
   "source": [
    "From the dataset, we've been able to see the mean and a statistical summary of the dataset. We have also observed that the minimum value of the sentiment is **-1** while the maximum value is **2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a58a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null objects in train data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e541ad9",
   "metadata": {},
   "source": [
    "The dataset has no null values which means all entries were appropriately recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd32b1",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Feature Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978af251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all tweets into lower case\n",
    "def lower_case(text):\n",
    "    text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0bfc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7996d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message']=df['message'].apply (lambda x: lower_case(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d29dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Before balancing our data\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='sentiment', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3462d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate minority and majority classes and name the sentiments\n",
    "News=df[df['sentiment']==2]\n",
    "Pro=df[df['sentiment']==1]\n",
    "Neutral=df[df['sentiment']==0]\n",
    "Anti=df[df['sentiment']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ada005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3640, 8530, 2353, 1296)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the lengths of all target values\n",
    "len(News), len(Pro), len(Neutral), len(Anti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df6029",
   "metadata": {},
   "source": [
    "With the varying target lengths, we discovered the data is imbalanced. We will balance the data using the upward resampling method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59f69f",
   "metadata": {},
   "source": [
    "**Dealing with Imbalanced Data - Balancing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d786ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsample the leading sentiment\n",
    "def sampling(x, y, z):\n",
    "    News_upsampled = resample(x,\n",
    "                              replace=True, # sample without replacement (no need to duplicate observations)\n",
    "                              n_samples=len(Pro), # match number in minority class\n",
    "                              random_state=27) # reproducible results\n",
    "    Neutral_upsampled = resample(y,\n",
    "                              replace=True, # sample without replacement (no need to duplicate observations)\n",
    "                              n_samples=len(Pro), # match number in minority class\n",
    "                              random_state=27) # reproducible results\n",
    "    Anti_upsampled = resample(z,\n",
    "                              replace=True, # sample without replacement (no need to duplicate observations)\n",
    "                              n_samples=len(Pro), # match number in minority class\n",
    "                              random_state=27) # reproducible results\n",
    "\n",
    "    # Combine downsampled majority class with minority class\n",
    "    final_downsampled = pd.concat([News_upsampled, Neutral_upsampled, Anti_upsampled, Pro])\n",
    "    return final_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba0d83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=sampling(News,Neutral,Anti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137e89a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "      <td>@cbcquirks #quirkquestions should canada go ah...</td>\n",
       "      <td>634603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @thinkprogress: interior scientist says the...</td>\n",
       "      <td>793130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @markdistef: senator malcolm roberts to bre...</td>\n",
       "      <td>990850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @sciam: for the third year in a row, the ca...</td>\n",
       "      <td>418438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @antarcticreport: john kerry leaves nz for ...</td>\n",
       "      <td>29803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>1</td>\n",
       "      <td>#scottpruit climate change comments would be l...</td>\n",
       "      <td>447067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @stephenschlegel: she's thinking about how ...</td>\n",
       "      <td>426353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @sierraclub: 2016: hottest year in history....</td>\n",
       "      <td>989478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @thinkprogress: epa head falsely claims car...</td>\n",
       "      <td>442853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @ezlusztig: they took down the material on ...</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid\n",
       "4401           2  @cbcquirks #quirkquestions should canada go ah...   634603\n",
       "11162          2  rt @thinkprogress: interior scientist says the...   793130\n",
       "3062           2  rt @markdistef: senator malcolm roberts to bre...   990850\n",
       "5669           2  rt @sciam: for the third year in a row, the ca...   418438\n",
       "13403          2  rt @antarcticreport: john kerry leaves nz for ...    29803\n",
       "...          ...                                                ...      ...\n",
       "15807          1  #scottpruit climate change comments would be l...   447067\n",
       "15811          1  rt @stephenschlegel: she's thinking about how ...   426353\n",
       "15812          1  rt @sierraclub: 2016: hottest year in history....   989478\n",
       "15813          1  rt @thinkprogress: epa head falsely claims car...   442853\n",
       "15814          1  rt @ezlusztig: they took down the material on ...    22001\n",
       "\n",
       "[34120 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfeb8427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    8530\n",
       " 1    8530\n",
       " 2    8530\n",
       "-1    8530\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new class counts\n",
    "df1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f93f3b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#After balancing the data\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='sentiment', data=df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392117ec",
   "metadata": {},
   "source": [
    "We upscaled the data to balance with the Pro sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80494dba",
   "metadata": {},
   "source": [
    "## Cleaning the tweet text - removing noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1154c1",
   "metadata": {},
   "source": [
    "Removing noise (i.e. unneccesary information) is a key part of getting the data into a usable format. \n",
    "For this dataset, we will be:\n",
    "making everything lower case\n",
    "removing punctuation\n",
    "removing emails and hashtags\n",
    "removing urls or website links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ee56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove urls\n",
    "def remove_website(text):\n",
    "    text = re.sub(r\"'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\",\"\", text)\n",
    "    text = \"\".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f99fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove email\n",
    "def remove_email(text):\n",
    "    text = re.sub(r\"@[\\w\\.-]+\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6838946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hashtags\n",
    "def remove_hashtags(text):\n",
    "    text = re.sub(r\"#\\w+\",\"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8bcd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove other unique characters\n",
    "def remove_unique_char(text):\n",
    "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f58f8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop = stopwords.words('english')\n",
    "    text = \" \".join([word for word in text.split() if word not in (stop)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e631dd",
   "metadata": {},
   "source": [
    "**Applying the above functions to the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac9b1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df1['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['message']=df1['message'].apply (lambda x: remove_website(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f672edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['message']=df1['message'].apply (lambda x: remove_email(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c5e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['message']=df1['message'].apply (lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f27f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['message']=df1['message'].apply (lambda x: remove_hashtags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd751813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['message']=df1['message'].apply (lambda x: remove_unique_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bf4219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "      <td>canada go ahead carbon tax usa russia china n...</td>\n",
       "      <td>634603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>2</td>\n",
       "      <td>interior scientist says agency retaliated sp...</td>\n",
       "      <td>793130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>senator malcolm roberts breitbart climate ch...</td>\n",
       "      <td>990850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>2</td>\n",
       "      <td>third year row carbon dioxide emissions driv...</td>\n",
       "      <td>418438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>2</td>\n",
       "      <td>john kerry leaves nz mcmurdo amp south pole ...</td>\n",
       "      <td>29803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>1</td>\n",
       "      <td>climate change comments would like nasa sayin...</td>\n",
       "      <td>447067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>1</td>\n",
       "      <td>thinking going die husband believe climate c...</td>\n",
       "      <td>426353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 hottest year history also 2016 182 memb...</td>\n",
       "      <td>989478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>1</td>\n",
       "      <td>epa head falsely claims carbon emissions are...</td>\n",
       "      <td>442853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>took material global warming lgbt rights hea...</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid\n",
       "4401           2   canada go ahead carbon tax usa russia china n...   634603\n",
       "11162          2    interior scientist says agency retaliated sp...   793130\n",
       "3062           2    senator malcolm roberts breitbart climate ch...   990850\n",
       "5669           2    third year row carbon dioxide emissions driv...   418438\n",
       "13403          2    john kerry leaves nz mcmurdo amp south pole ...    29803\n",
       "...          ...                                                ...      ...\n",
       "15807          1   climate change comments would like nasa sayin...   447067\n",
       "15811          1    thinking going die husband believe climate c...   426353\n",
       "15812          1    2016 hottest year history also 2016 182 memb...   989478\n",
       "15813          1    epa head falsely claims carbon emissions are...   442853\n",
       "15814          1    took material global warming lgbt rights hea...    22001\n",
       "\n",
       "[34120 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaned data\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a749676",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4c24e",
   "metadata": {},
   "source": [
    "A tokeniser divides text into a sequence of tokens, which roughly correspond to \"words\". We will use tokenisers to clean up the data, making it ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c8aad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df1['tokens'] = df1['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7936c421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "      <td>canada go ahead carbon tax usa russia china n...</td>\n",
       "      <td>634603</td>\n",
       "      <td>[canada, go, ahead, carbon, tax, usa, russia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>2</td>\n",
       "      <td>interior scientist says agency retaliated sp...</td>\n",
       "      <td>793130</td>\n",
       "      <td>[interior, scientist, says, agency, retaliated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>senator malcolm roberts breitbart climate ch...</td>\n",
       "      <td>990850</td>\n",
       "      <td>[senator, malcolm, roberts, breitbart, climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>2</td>\n",
       "      <td>third year row carbon dioxide emissions driv...</td>\n",
       "      <td>418438</td>\n",
       "      <td>[third, year, row, carbon, dioxide, emissions,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>2</td>\n",
       "      <td>john kerry leaves nz mcmurdo amp south pole ...</td>\n",
       "      <td>29803</td>\n",
       "      <td>[john, kerry, leaves, nz, mcmurdo, amp, south,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>1</td>\n",
       "      <td>climate change comments would like nasa sayin...</td>\n",
       "      <td>447067</td>\n",
       "      <td>[climate, change, comments, would, like, nasa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>1</td>\n",
       "      <td>thinking going die husband believe climate c...</td>\n",
       "      <td>426353</td>\n",
       "      <td>[thinking, going, die, husband, believe, clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 hottest year history also 2016 182 memb...</td>\n",
       "      <td>989478</td>\n",
       "      <td>[2016, hottest, year, history, also, 2016, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>1</td>\n",
       "      <td>epa head falsely claims carbon emissions are...</td>\n",
       "      <td>442853</td>\n",
       "      <td>[epa, head, falsely, claims, carbon, emissions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>took material global warming lgbt rights hea...</td>\n",
       "      <td>22001</td>\n",
       "      <td>[took, material, global, warming, lgbt, rights...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "4401           2   canada go ahead carbon tax usa russia china n...   634603   \n",
       "11162          2    interior scientist says agency retaliated sp...   793130   \n",
       "3062           2    senator malcolm roberts breitbart climate ch...   990850   \n",
       "5669           2    third year row carbon dioxide emissions driv...   418438   \n",
       "13403          2    john kerry leaves nz mcmurdo amp south pole ...    29803   \n",
       "...          ...                                                ...      ...   \n",
       "15807          1   climate change comments would like nasa sayin...   447067   \n",
       "15811          1    thinking going die husband believe climate c...   426353   \n",
       "15812          1    2016 hottest year history also 2016 182 memb...   989478   \n",
       "15813          1    epa head falsely claims carbon emissions are...   442853   \n",
       "15814          1    took material global warming lgbt rights hea...    22001   \n",
       "\n",
       "                                                  tokens  \n",
       "4401   [canada, go, ahead, carbon, tax, usa, russia, ...  \n",
       "11162  [interior, scientist, says, agency, retaliated...  \n",
       "3062   [senator, malcolm, roberts, breitbart, climate...  \n",
       "5669   [third, year, row, carbon, dioxide, emissions,...  \n",
       "13403  [john, kerry, leaves, nz, mcmurdo, amp, south,...  \n",
       "...                                                  ...  \n",
       "15807  [climate, change, comments, would, like, nasa,...  \n",
       "15811  [thinking, going, die, husband, believe, clima...  \n",
       "15812  [2016, hottest, year, history, also, 2016, 182...  \n",
       "15813  [epa, head, falsely, claims, carbon, emissions...  \n",
       "15814  [took, material, global, warming, lgbt, rights...  \n",
       "\n",
       "[34120 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa548d9",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7e4a6",
   "metadata": {},
   "source": [
    "Lemmatizing is the process of grouping words of similar meaning together. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma.\n",
    "Sometimes you will wind up with a very similar word, but other times you will wind up with a completely different word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07680b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f97a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df1_lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e3a74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lemma'] = df1['tokens'].apply(df1_lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "305e03cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "      <td>canada go ahead carbon tax usa russia china n...</td>\n",
       "      <td>634603</td>\n",
       "      <td>[canada, go, ahead, carbon, tax, usa, russia, ...</td>\n",
       "      <td>[canada, go, ahead, carbon, tax, usa, russia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>2</td>\n",
       "      <td>interior scientist says agency retaliated sp...</td>\n",
       "      <td>793130</td>\n",
       "      <td>[interior, scientist, says, agency, retaliated...</td>\n",
       "      <td>[interior, scientist, say, agency, retaliated,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>senator malcolm roberts breitbart climate ch...</td>\n",
       "      <td>990850</td>\n",
       "      <td>[senator, malcolm, roberts, breitbart, climate...</td>\n",
       "      <td>[senator, malcolm, robert, breitbart, climate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>2</td>\n",
       "      <td>third year row carbon dioxide emissions driv...</td>\n",
       "      <td>418438</td>\n",
       "      <td>[third, year, row, carbon, dioxide, emissions,...</td>\n",
       "      <td>[third, year, row, carbon, dioxide, emission, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>2</td>\n",
       "      <td>john kerry leaves nz mcmurdo amp south pole ...</td>\n",
       "      <td>29803</td>\n",
       "      <td>[john, kerry, leaves, nz, mcmurdo, amp, south,...</td>\n",
       "      <td>[john, kerry, leaf, nz, mcmurdo, amp, south, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>1</td>\n",
       "      <td>climate change comments would like nasa sayin...</td>\n",
       "      <td>447067</td>\n",
       "      <td>[climate, change, comments, would, like, nasa,...</td>\n",
       "      <td>[climate, change, comment, would, like, nasa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>1</td>\n",
       "      <td>thinking going die husband believe climate c...</td>\n",
       "      <td>426353</td>\n",
       "      <td>[thinking, going, die, husband, believe, clima...</td>\n",
       "      <td>[thinking, going, die, husband, believe, clima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 hottest year history also 2016 182 memb...</td>\n",
       "      <td>989478</td>\n",
       "      <td>[2016, hottest, year, history, also, 2016, 182...</td>\n",
       "      <td>[2016, hottest, year, history, also, 2016, 182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>1</td>\n",
       "      <td>epa head falsely claims carbon emissions are...</td>\n",
       "      <td>442853</td>\n",
       "      <td>[epa, head, falsely, claims, carbon, emissions...</td>\n",
       "      <td>[epa, head, falsely, claim, carbon, emission, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>took material global warming lgbt rights hea...</td>\n",
       "      <td>22001</td>\n",
       "      <td>[took, material, global, warming, lgbt, rights...</td>\n",
       "      <td>[took, material, global, warming, lgbt, right,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "4401           2   canada go ahead carbon tax usa russia china n...   634603   \n",
       "11162          2    interior scientist says agency retaliated sp...   793130   \n",
       "3062           2    senator malcolm roberts breitbart climate ch...   990850   \n",
       "5669           2    third year row carbon dioxide emissions driv...   418438   \n",
       "13403          2    john kerry leaves nz mcmurdo amp south pole ...    29803   \n",
       "...          ...                                                ...      ...   \n",
       "15807          1   climate change comments would like nasa sayin...   447067   \n",
       "15811          1    thinking going die husband believe climate c...   426353   \n",
       "15812          1    2016 hottest year history also 2016 182 memb...   989478   \n",
       "15813          1    epa head falsely claims carbon emissions are...   442853   \n",
       "15814          1    took material global warming lgbt rights hea...    22001   \n",
       "\n",
       "                                                  tokens  \\\n",
       "4401   [canada, go, ahead, carbon, tax, usa, russia, ...   \n",
       "11162  [interior, scientist, says, agency, retaliated...   \n",
       "3062   [senator, malcolm, roberts, breitbart, climate...   \n",
       "5669   [third, year, row, carbon, dioxide, emissions,...   \n",
       "13403  [john, kerry, leaves, nz, mcmurdo, amp, south,...   \n",
       "...                                                  ...   \n",
       "15807  [climate, change, comments, would, like, nasa,...   \n",
       "15811  [thinking, going, die, husband, believe, clima...   \n",
       "15812  [2016, hottest, year, history, also, 2016, 182...   \n",
       "15813  [epa, head, falsely, claims, carbon, emissions...   \n",
       "15814  [took, material, global, warming, lgbt, rights...   \n",
       "\n",
       "                                                   lemma  \n",
       "4401   [canada, go, ahead, carbon, tax, usa, russia, ...  \n",
       "11162  [interior, scientist, say, agency, retaliated,...  \n",
       "3062   [senator, malcolm, robert, breitbart, climate,...  \n",
       "5669   [third, year, row, carbon, dioxide, emission, ...  \n",
       "13403  [john, kerry, leaf, nz, mcmurdo, amp, south, p...  \n",
       "...                                                  ...  \n",
       "15807  [climate, change, comment, would, like, nasa, ...  \n",
       "15811  [thinking, going, die, husband, believe, clima...  \n",
       "15812  [2016, hottest, year, history, also, 2016, 182...  \n",
       "15813  [epa, head, falsely, claim, carbon, emission, ...  \n",
       "15814  [took, material, global, warming, lgbt, right,...  \n",
       "\n",
       "[34120 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b2626ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the lemmas together\n",
    "df1['lemma']=df1['lemma'].apply(lambda tokens: \" \".join(map(str, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cb3bf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4401     canada go ahead carbon tax usa russia china no...\n",
       "11162    interior scientist say agency retaliated speak...\n",
       "3062     senator malcolm robert breitbart climate chang...\n",
       "5669     third year row carbon dioxide emission drive c...\n",
       "13403    john kerry leaf nz mcmurdo amp south pole meet...\n",
       "                               ...                        \n",
       "15807    climate change comment would like nasa saying ...\n",
       "15811    thinking going die husband believe climate change\n",
       "15812    2016 hottest year history also 2016 182 member...\n",
       "15813    epa head falsely claim carbon emission arent c...\n",
       "15814    took material global warming lgbt right health...\n",
       "Name: lemma, Length: 34120, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de7dc1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>2</td>\n",
       "      <td>canada go ahead carbon tax usa russia china n...</td>\n",
       "      <td>634603</td>\n",
       "      <td>[canada, go, ahead, carbon, tax, usa, russia, ...</td>\n",
       "      <td>canada go ahead carbon tax usa russia china no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>2</td>\n",
       "      <td>interior scientist says agency retaliated sp...</td>\n",
       "      <td>793130</td>\n",
       "      <td>[interior, scientist, says, agency, retaliated...</td>\n",
       "      <td>interior scientist say agency retaliated speak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>2</td>\n",
       "      <td>senator malcolm roberts breitbart climate ch...</td>\n",
       "      <td>990850</td>\n",
       "      <td>[senator, malcolm, roberts, breitbart, climate...</td>\n",
       "      <td>senator malcolm robert breitbart climate chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>2</td>\n",
       "      <td>third year row carbon dioxide emissions driv...</td>\n",
       "      <td>418438</td>\n",
       "      <td>[third, year, row, carbon, dioxide, emissions,...</td>\n",
       "      <td>third year row carbon dioxide emission drive c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>2</td>\n",
       "      <td>john kerry leaves nz mcmurdo amp south pole ...</td>\n",
       "      <td>29803</td>\n",
       "      <td>[john, kerry, leaves, nz, mcmurdo, amp, south,...</td>\n",
       "      <td>john kerry leaf nz mcmurdo amp south pole meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>1</td>\n",
       "      <td>climate change comments would like nasa sayin...</td>\n",
       "      <td>447067</td>\n",
       "      <td>[climate, change, comments, would, like, nasa,...</td>\n",
       "      <td>climate change comment would like nasa saying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15811</th>\n",
       "      <td>1</td>\n",
       "      <td>thinking going die husband believe climate c...</td>\n",
       "      <td>426353</td>\n",
       "      <td>[thinking, going, die, husband, believe, clima...</td>\n",
       "      <td>thinking going die husband believe climate change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15812</th>\n",
       "      <td>1</td>\n",
       "      <td>2016 hottest year history also 2016 182 memb...</td>\n",
       "      <td>989478</td>\n",
       "      <td>[2016, hottest, year, history, also, 2016, 182...</td>\n",
       "      <td>2016 hottest year history also 2016 182 member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>1</td>\n",
       "      <td>epa head falsely claims carbon emissions are...</td>\n",
       "      <td>442853</td>\n",
       "      <td>[epa, head, falsely, claims, carbon, emissions...</td>\n",
       "      <td>epa head falsely claim carbon emission arent c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>took material global warming lgbt rights hea...</td>\n",
       "      <td>22001</td>\n",
       "      <td>[took, material, global, warming, lgbt, rights...</td>\n",
       "      <td>took material global warming lgbt right health...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid  \\\n",
       "4401           2   canada go ahead carbon tax usa russia china n...   634603   \n",
       "11162          2    interior scientist says agency retaliated sp...   793130   \n",
       "3062           2    senator malcolm roberts breitbart climate ch...   990850   \n",
       "5669           2    third year row carbon dioxide emissions driv...   418438   \n",
       "13403          2    john kerry leaves nz mcmurdo amp south pole ...    29803   \n",
       "...          ...                                                ...      ...   \n",
       "15807          1   climate change comments would like nasa sayin...   447067   \n",
       "15811          1    thinking going die husband believe climate c...   426353   \n",
       "15812          1    2016 hottest year history also 2016 182 memb...   989478   \n",
       "15813          1    epa head falsely claims carbon emissions are...   442853   \n",
       "15814          1    took material global warming lgbt rights hea...    22001   \n",
       "\n",
       "                                                  tokens  \\\n",
       "4401   [canada, go, ahead, carbon, tax, usa, russia, ...   \n",
       "11162  [interior, scientist, says, agency, retaliated...   \n",
       "3062   [senator, malcolm, roberts, breitbart, climate...   \n",
       "5669   [third, year, row, carbon, dioxide, emissions,...   \n",
       "13403  [john, kerry, leaves, nz, mcmurdo, amp, south,...   \n",
       "...                                                  ...   \n",
       "15807  [climate, change, comments, would, like, nasa,...   \n",
       "15811  [thinking, going, die, husband, believe, clima...   \n",
       "15812  [2016, hottest, year, history, also, 2016, 182...   \n",
       "15813  [epa, head, falsely, claims, carbon, emissions...   \n",
       "15814  [took, material, global, warming, lgbt, rights...   \n",
       "\n",
       "                                                   lemma  \n",
       "4401   canada go ahead carbon tax usa russia china no...  \n",
       "11162  interior scientist say agency retaliated speak...  \n",
       "3062   senator malcolm robert breitbart climate chang...  \n",
       "5669   third year row carbon dioxide emission drive c...  \n",
       "13403  john kerry leaf nz mcmurdo amp south pole meet...  \n",
       "...                                                  ...  \n",
       "15807  climate change comment would like nasa saying ...  \n",
       "15811  thinking going die husband believe climate change  \n",
       "15812  2016 hottest year history also 2016 182 member...  \n",
       "15813  epa head falsely claim carbon emission arent c...  \n",
       "15814  took material global warming lgbt right health...  \n",
       "\n",
       "[34120 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff001df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X and y variables using the lemmas and sentiment values\n",
    "X=df1.lemma.values\n",
    "y=df1.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85986bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34120,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the cleaned data\n",
    "df1.message.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b33d92",
   "metadata": {},
   "source": [
    "## Tuning the vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e25aa",
   "metadata": {},
   "source": [
    "This function will convert a collection of documents (rows of text) into a matrix of token counts. Here is the parameter that we tuned: \n",
    "stop_words: string 'english', list, or None (default)\n",
    "If 'english', a built-in stop word list for English is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52e91353",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english',\n",
    "                             min_df=2,\n",
    "                             max_df=0.5,\n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "train_x_vecs = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c21da2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34120, 39405)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the tuned data using CountVectorizer\n",
    "train_x_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0753d",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modeling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d51fcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x_vecs, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed8d6896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the MNB is: 0.8826201641266119\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.98      0.94      1671\n",
      "           0       0.92      0.86      0.89      1722\n",
      "           1       0.82      0.81      0.81      1724\n",
      "           2       0.88      0.89      0.89      1707\n",
      "\n",
      "    accuracy                           0.88      6824\n",
      "   macro avg       0.88      0.88      0.88      6824\n",
      "weighted avg       0.88      0.88      0.88      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifying with the multinomial bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score of the MNB is:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c21b5",
   "metadata": {},
   "source": [
    "**Multinomial Bayes Classifier**\n",
    "It is used for discrete counts. For example, let’s say, we have a text classification problem. Here we can consider bernoulli trials which is one step further and instead of “word occurring in the document”, we have “count how often word occurs in the document”, you can think of it as “number of times outcome number x_i is observed over the n trials”.\n",
    "\n",
    "We get an accuracy f1-score of 0.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb07c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the log is: 0.9339097303634232\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.99      0.98      1671\n",
      "           0       0.92      0.96      0.94      1722\n",
      "           1       0.91      0.84      0.87      1724\n",
      "           2       0.92      0.95      0.93      1707\n",
      "\n",
      "    accuracy                           0.93      6824\n",
      "   macro avg       0.93      0.93      0.93      6824\n",
      "weighted avg       0.93      0.93      0.93      6824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianaokeyo/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Classifying with logistic regression\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train, y_train)\n",
    "y_pred_L = clf_log.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score of the log is:\", accuracy_score(y_test, y_pred_L))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred_L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce777ef",
   "metadata": {},
   "source": [
    "**Logistic Regression** makes use of a common S-shaped curve known as the logistic function. This curve is commonly known as a sigmoid. It solves the problem for the following reasons:\n",
    "It squeezes the range of output values to exist only between 0 and 1.\n",
    "It has a point of inflection, which can be used to separate the feature space into two distinct areas (one for each class).\n",
    "It has shallow gradients at both its top and bottom, which can be mapped to zeroes or ones respectively with little ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c74cd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the GNB is: 0.8761723329425557\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.94      0.95      1671\n",
      "           0       0.94      0.83      0.88      1722\n",
      "           1       0.74      0.87      0.80      1724\n",
      "           2       0.90      0.87      0.88      1707\n",
      "\n",
      "    accuracy                           0.88      6824\n",
      "   macro avg       0.89      0.88      0.88      6824\n",
      "weighted avg       0.88      0.88      0.88      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifying with gaussiona bernoulli\n",
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_B = gnb.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score of the GNB is:\", accuracy_score(y_test, y_pred_B))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7c380",
   "metadata": {},
   "source": [
    "**Gaussian** It is used in classification and it assumes that features follow a normal distribution. We get an accuracy f1-score of 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be927f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the SVC is: 0.9415298944900352\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      1671\n",
      "           0       0.93      0.97      0.95      1722\n",
      "           1       0.92      0.86      0.89      1724\n",
      "           2       0.93      0.95      0.94      1707\n",
      "\n",
      "    accuracy                           0.94      6824\n",
      "   macro avg       0.94      0.94      0.94      6824\n",
      "weighted avg       0.94      0.94      0.94      6824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifying with support vector classifier\n",
    "svc = SVC(kernel='rbf', C=12)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score of the SVC is:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56430d6e",
   "metadata": {},
   "source": [
    "**Support vector classifier** algorithm is to find a hyperplane in the N-dimensional space (N is the number of features) that distinctively classifies the data points. The objective is to find a plane that has the maximum margin i.e the maximum distance between data points of both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54320fb8",
   "metadata": {},
   "source": [
    "## Prediction with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddc1dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading test data\n",
    "test_df =pd.read_csv('test_with_no_labels.csv') # load the data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6dfdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning values to tweetid\n",
    "tweetid = test_df.tweetid.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157c035",
   "metadata": {},
   "source": [
    "## Cleaning the unseen data - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b4fc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=test_df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a3b3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing URls\n",
    "test_df['message']=test_df['message'].apply (lambda d: remove_website(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6ff202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing emails\n",
    "test_df['message']=test_df['message'].apply (lambda d: remove_email(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ec7ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "test_df['message']=test_df['message'].apply (lambda d: remove_stopwords(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a2ddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing hashtags from tweet messages\n",
    "test_df['message']=test_df['message'].apply (lambda d: remove_hashtags(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7506c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing other unique characters\n",
    "test_df['message']=test_df['message'].apply (lambda d: remove_unique_char1(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "368212f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying tokenisation to the test data\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "test_df['tokens'] = test_df['message'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8751e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lemma(words, lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13ac3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying lemmatization to the test data\n",
    "test_df['lemma'] = test_df['tokens'].apply(test_lemma, args=(lemmatizer, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d889a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the lemmas on the test data\n",
    "test_df['lemma']=test_df['lemma'].apply(lambda tokens: \" \".join(map(str, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad110f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe looking China make sure alone fighting ...</td>\n",
       "      <td>169760</td>\n",
       "      <td>[Europe, looking, China, make, sure, alone, fi...</td>\n",
       "      <td>Europe looking China make sure alone fighting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine polling staffers climate change womens...</td>\n",
       "      <td>35326</td>\n",
       "      <td>[Combine, polling, staffers, climate, change, ...</td>\n",
       "      <td>Combine polling staffer climate change woman r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary unimpeachable evidence climate chang...</td>\n",
       "      <td>224985</td>\n",
       "      <td>[The, scary, unimpeachable, evidence, climate,...</td>\n",
       "      <td>The scary unimpeachable evidence climate chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  Europe looking China make sure alone fighting ...   169760   \n",
       "1  Combine polling staffers climate change womens...    35326   \n",
       "2  The scary unimpeachable evidence climate chang...   224985   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Europe, looking, China, make, sure, alone, fi...   \n",
       "1  [Combine, polling, staffers, climate, change, ...   \n",
       "2  [The, scary, unimpeachable, evidence, climate,...   \n",
       "\n",
       "                                               lemma  \n",
       "0  Europe looking China make sure alone fighting ...  \n",
       "1  Combine polling staffer climate change woman r...  \n",
       "2  The scary unimpeachable evidence climate chang...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "495bdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.drop(['tweetid','message','tokens'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01f27e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianaokeyo/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Applying the CountVectorizer to test data\n",
    "vectorizer = CountVectorizer(vocabulary = vect.get_feature_names(), stop_words='english',\n",
    "                             min_df=2,\n",
    "                             max_df=0.5,\n",
    "                             ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b7471b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_vecs = vectorizer.transform(test_df.lemma.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eea14b",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Classifier Model Selection\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "183efbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling the test data with support vector classifier\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_s = svc.predict(test_x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78a0847b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianaokeyo/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelling the test data with logistic regression\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70608461",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_L = clf_log.predict(test_x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb737f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling the test data with gnb classifier\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_b = gnb.predict(test_x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79d9bbda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetid  sentiment\n",
       "0   169760          1\n",
       "1    35326          1\n",
       "2   224985          1\n",
       "3   476263          1\n",
       "4   872928          0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(list(zip(tweetid, y_pred_s)), columns = ['tweetid','sentiment'])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "42c06c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aad707b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('New submission1.csv', index_label = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7158bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.8.1-py2.py3-none-any.whl (10.1 MB)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (20.9)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-win_amd64.whl (16.1 MB)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (2.25.1)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (1.2.4)\n",
      "Requirement already satisfied: click<8.1,>=7.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "Requirement already satisfied: toml in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-4.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Collecting protobuf!=3.11,>=3.6.0\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (8.2.0)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (20.3.0)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: watchdog in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (1.0.2)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (3.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\amand\\anaconda3\\lib\\site-packages (from streamlit) (1.20.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\amand\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\amand\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.4.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2021.1)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.4)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.22.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (6.1.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.17)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.8.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.0.6)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\amand\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.4)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.10.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.0.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\amand\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\amand\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\amand\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from requests->streamlit) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from requests->streamlit) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amand\\anaconda3\\lib\\site-packages (from requests->streamlit) (2020.12.5)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: blinker\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13451 sha256=0e792960c8dabd4445f6ea9c66364fb5a056f296ba83376c5591beec56ce8842\n",
      "  Stored in directory: c:\\users\\amand\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "Successfully built blinker\n",
      "Installing collected packages: tzdata, smmap, backports.zoneinfo, pytz-deprecation-shim, gitdb, validators, tzlocal, semver, pympler, pydeck, pyarrow, protobuf, gitpython, cachetools, blinker, altair, streamlit\n",
      "Successfully installed altair-4.2.0 backports.zoneinfo-0.2.1 blinker-1.4 cachetools-5.0.0 gitdb-4.0.9 gitpython-3.1.27 protobuf-3.19.4 pyarrow-7.0.0 pydeck-0.7.1 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 semver-2.13.0 smmap-5.0.0 streamlit-1.8.1 tzdata-2022.1 tzlocal-4.1 validators-0.18.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaaa1a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c7a1b683aa76>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-c7a1b683aa76>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    streamlit hello\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a840cd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-58228eb44eba>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-58228eb44eba>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    $streamlit hello\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$streamlit hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef52a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b175cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
